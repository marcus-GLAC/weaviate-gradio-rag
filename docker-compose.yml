version: '3.8'

services:
    transformers-inference:
        ports:
            - 8000:8080
        container_name: embedding-model
        image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1
        restart: always
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8080/"]
            interval: 30s
            timeout: 10s
            retries: 3

    weaviate:
        image: semitechnologies/weaviate:1.29.1
        ports:
            - 8080:8080
        restart: always
        container_name: weaviate-db
        environment:
            QUERY_DEFAULTS_LIMIT: 25
            AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
            PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
            DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
            ENABLE_MODULES: 'text2vec-transformers'
            TRANSFORMERS_INFERENCE_API: 'http://transformers-inference:8080'
            LOG_LEVEL: 'debug'
        volumes:
            - weaviate_data:/var/lib/weaviate
        depends_on:
            - transformers-inference
        healthcheck:
            test: ["CMD", "curl", "-f", "http://localhost:8080/v1/meta"]
            interval: 30s
            timeout: 10s
            retries: 3
    
    app:
        build:
            context: .
            dockerfile: Dockerfile
        ports:
            - "7860:7860"
        container_name: rag-app
        restart: always
        environment:
            - WEAVIATE_URL=http://weaviate:8080
            - GRADIO_SERVER_NAME=0.0.0.0
            - GRADIO_SERVER_PORT=7860
            - GRADIO_ROOT_PATH=/
            - GRADIO_ALLOWED_ORIGINS=*
        env_file:
            - .env
        volumes:
            - ./uploads:/app/uploads
        depends_on:
            - weaviate
            - transformers-inference

volumes:
    weaviate_data:
        driver: local
    uploads:
        driver: local